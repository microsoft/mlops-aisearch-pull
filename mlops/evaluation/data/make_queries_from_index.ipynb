{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "if not load_dotenv():\n",
    "    print(\"No .env file found, was this intentional?\")\n",
    "else:\n",
    "    print(\".env found! Loading environement variables.\")\n",
    "\n",
    "env_vars = [\n",
    "    \"ACS_API_KEY\",\n",
    "    \"AZURE_SEARCH_SERVICE_ENDPOINT\",\n",
    "    \"AOAI_BASE_ENDPOINT\",\n",
    "    \"AOAI_API_KEY\",\n",
    "]\n",
    "\n",
    "for env_var in env_vars:\n",
    "    if os.getenv(env_var) is None:\n",
    "        print(f\"Missing environment variable: {env_var}\")\n",
    "        exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a chunk, create a query with ground truth (filename, page_number)\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "def create_query(chunk, filename, page_number):\n",
    "    api_key = os.environ.get(\"AOAI_API_KEY\")\n",
    "    api_endpoint = os.environ.get(\"AOAI_BASE_ENDPOINT\")\n",
    "    api_version = \"2023-07-01-preview\"\n",
    "\n",
    "    GPT_MODEL_DEPLOYMENT = \"gpt-35-turbo\"\n",
    "\n",
    "    TEMPERATURE = 0.2\n",
    "    MAX_TOKENS = 2000\n",
    "\n",
    "    GENERATE_QUESTION_PROMPT = \"\"\"You are an AI assistant.\n",
    "    Your job is to generate one relevant question-answer pair based only on the current context:\n",
    "\n",
    "    ```\n",
    "    {current_context}\n",
    "    ```\n",
    "\n",
    "    - Use this format: Question|Answer\n",
    "    - Make sure to output the content in the Question and Answer fields are on the same line.\n",
    "    \"\"\"\n",
    "\n",
    "    messages = []\n",
    "    prompt = GENERATE_QUESTION_PROMPT.format(current_context=chunk)\n",
    "\n",
    "    messages.append(\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": prompt\n",
    "        }\n",
    "    )\n",
    "\n",
    "    client = AzureOpenAI(api_key=api_key, api_version=api_version, azure_endpoint=api_endpoint)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=GPT_MODEL_DEPLOYMENT,\n",
    "        messages=messages,\n",
    "        temperature=TEMPERATURE,\n",
    "        max_tokens=MAX_TOKENS,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=None,\n",
    "    )\n",
    "    try:\n",
    "        query, answer = response.choices[0].message.content.split(\"|\")\n",
    "        if query == \"\" or answer == \"\":\n",
    "            print(f\"Unable to generate qa from {response.choices[0].message.content}\")\n",
    "            return None\n",
    "    except:\n",
    "        print(f\"Unable to generate qa from {response.choices[0].message.content}\")\n",
    "        return None\n",
    "\n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"answer\": answer,\n",
    "        \"sources\": [\n",
    "            {\n",
    "                \"filename\":filename,\n",
    "                \"page_number\": page_number\n",
    "            }\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = create_query(\"The quick brown fox jumps over the lazy dog.\", \"test.pdf\", 1)\n",
    "result\n",
    "\n",
    "results = []\n",
    "results.append(result)\n",
    "results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write queries to file\n",
    "import json\n",
    "\n",
    "def write_queries_to_file(results, filename):\n",
    "    with open(filename, \"w\") as f:\n",
    "        for result in results:\n",
    "            f.write(json.dumps(result))\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve chunks and create query for each\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents.indexes import SearchIndexerClient\n",
    "from azure.search.documents import SearchClient\n",
    "\n",
    "acs_endpoint = os.getenv(\"AZURE_SEARCH_SERVICE_ENDPOINT\")\n",
    "acs_key = os.getenv(\"ACS_API_KEY\")\n",
    "index_name = \"search-eval-index\"\n",
    "\n",
    "search_indexer_client = SearchIndexerClient(acs_endpoint, AzureKeyCredential(acs_key))\n",
    "search_client = SearchClient(acs_endpoint, index_name, AzureKeyCredential(acs_key))\n",
    "\n",
    "search_results = search_client.search(search_text=\"*\")\n",
    "\n",
    "query_results = []\n",
    "for sr in search_results:\n",
    "    query_result = create_query(sr[\"content\"], sr[\"filename\"], sr[\"page_number\"])\n",
    "    if query_result is not None:\n",
    "        query_results.append(query_result)\n",
    "\n",
    "write_queries_to_file(query_results, \"./mlops/evaluation/data/queries.jsonl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
